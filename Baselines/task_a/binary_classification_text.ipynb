{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18996d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d2a56d",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e924032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 4)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '../../Data' ## path to the folder where the dataset is there\n",
    "\n",
    "csv_path_train = os.path.join(DATA_PATH, 'split_train.csv')\n",
    "csv_path_val = os.path.join(DATA_PATH, 'split_val.csv')\n",
    "csv_path_test = os.path.join(DATA_PATH, 'split_test.csv')\n",
    "\n",
    "image_path = os.path.join(DATA_PATH, 'images')\n",
    "\n",
    "# text_data_column = 'Text Normalized'\n",
    "text_data_column = 'Text Transcription'\n",
    "\n",
    "def read_data_from_csv(path_name):\n",
    "\tdf = pd.read_csv(path_name, usecols=['file_name', 'misogynous', text_data_column], sep='\\t')\n",
    "\tpath = image_path+'/'\n",
    "\tdf['image_path'] = path + df['file_name']\n",
    "\n",
    "\treturn df\n",
    "\n",
    "## Reading data\n",
    "train_df = read_data_from_csv(csv_path_train)\n",
    "val_df = read_data_from_csv(csv_path_val)\n",
    "test_df = read_data_from_csv(csv_path_test)\n",
    "\n",
    "print(train_df.shape)\n",
    "target_names = ['non-misogynistic', 'misogynistic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2749355c",
   "metadata": {},
   "source": [
    "## Naive_Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4600b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ca5fc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(train_df[text_data_column], train_df['misogynous'])\n",
    "\n",
    "predicted_nb = text_clf.predict(test_df[text_data_column])\n",
    "score_nb = np.mean(predicted_nb == test_df['misogynous'])\n",
    "print(score_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32be05bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-misogynistic     0.8307    0.8066    0.8184       517\n",
      "    misogynistic     0.7992    0.8240    0.8114       483\n",
      "\n",
      "       micro avg     0.8150    0.8150    0.8150      1000\n",
      "       macro avg     0.8149    0.8153    0.8149      1000\n",
      "    weighted avg     0.8155    0.8150    0.8151      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['misogynous'], predicted_nb, target_names=target_names, digits =4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20d96e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-misogynistic      0.809     0.778     0.793       517\n",
      "    misogynistic      0.771     0.803     0.787       483\n",
      "\n",
      "       micro avg      0.790     0.790     0.790      1000\n",
      "       macro avg      0.790     0.790     0.790      1000\n",
      "    weighted avg      0.791     0.790     0.790      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes with Stemming\n",
    "text_clf = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(train_df[text_data_column], train_df['misogynous'])\n",
    "\n",
    "predicted_nb = text_clf.predict(test_df[text_data_column])\n",
    "score_nb = np.mean(predicted_nb == test_df['misogynous'])\n",
    "# print(predicted)\n",
    "print(score_nb)\n",
    "print(classification_report(test_df['misogynous'], predicted_nb, target_names=target_names, digits =3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da008b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-misogynistic: woman kitchen day work time women want cook meme cheat don clean peopl just like wife hous imgflip girlfriend com\n",
      "misogynistic: memegener man want kitchen meme don memecent just look imgflip make quickmem men net feminist woman like girl women com\n"
     ]
    }
   ],
   "source": [
    "## Analysis of the top words in \n",
    "import numpy as np\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.feature_log_prob_[i])[-20:]\n",
    "        print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
    "\n",
    "categories = ['non-misogynistic','misogynistic']\n",
    "show_top10(text_clf.named_steps['clf'], text_clf.named_steps['vect'], categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b69c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "753846b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00152367, 0.00161975, 0.00165073, 0.00165584, 0.00174221,\n",
       "       0.00189004, 0.00236661, 0.00243541, 0.0025502 , 0.00326558])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.sort(text_clf['clf'].feature_log_prob_[0])[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "cede8c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = text_clf['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "093c87fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.2752985 , -2.18216691, -2.06796397, ...,  2.6635885 ,\n",
       "        2.70756679,  3.19959238])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(classifier.feature_log_prob_[1]- classifier.feature_log_prob_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "504f0332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00208433, 0.00215492, 0.00220405, 0.00221154, 0.00254434,\n",
       "       0.00283106, 0.00327792, 0.00388127, 0.00532711, 0.00668653])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.sort(text_clf['clf'].feature_log_prob_[1])[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ec619",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64bb6169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srnangi/miniconda3/envs/cs229/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## SVM\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(train_df[text_data_column], train_df['misogynous'])\n",
    "predicted_svm = text_clf_svm.predict(test_df[text_data_column])\n",
    "score_svm = np.mean(predicted_svm == test_df['misogynous'])\n",
    "print(score_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e61bc294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-misogynistic     0.7593    0.8665    0.8094       517\n",
      "    misogynistic     0.8317    0.7060    0.7637       483\n",
      "\n",
      "       micro avg     0.7890    0.7890    0.7890      1000\n",
      "       macro avg     0.7955    0.7863    0.7866      1000\n",
      "    weighted avg     0.7943    0.7890    0.7873      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df['misogynous'], predicted_svm, target_names=target_names, digits =4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae337939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-misogynistic      0.750     0.897     0.817       517\n",
      "    misogynistic      0.861     0.679     0.759       483\n",
      "\n",
      "       micro avg      0.792     0.792     0.792      1000\n",
      "       macro avg      0.805     0.788     0.788      1000\n",
      "    weighted avg      0.803     0.792     0.789      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srnangi/miniconda3/envs/cs229/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## SVM new with stemming\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(train_df[text_data_column], train_df['misogynous'])\n",
    "predicted_svm = text_clf_svm.predict(test_df[text_data_column])\n",
    "score_svm = np.mean(predicted_svm == test_df['misogynous'])\n",
    "print(score_svm)\n",
    "print(classification_report(test_df['misogynous'], predicted_svm, target_names=target_names, digits =3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9640a394",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a9c2581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-misogynistic     0.7981    0.8259    0.8118       517\n",
      "    misogynistic     0.8065    0.7764    0.7911       483\n",
      "\n",
      "       micro avg     0.8020    0.8020    0.8020      1000\n",
      "       macro avg     0.8023    0.8012    0.8015      1000\n",
      "    weighted avg     0.8021    0.8020    0.8018      1000\n",
      "\n",
      "Accuracy = 0.802\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "                ('clf', LogisticRegression(solver='sag'))\n",
    "            ])\n",
    "\n",
    "lr_clf = LogReg_pipeline.fit(train_df[text_data_column], train_df['misogynous'])\n",
    "pred_lr = lr_clf.predict(test_df[text_data_column])\n",
    "print(classification_report(test_df['misogynous'], pred_lr, target_names=target_names, digits=4))\n",
    "acc_score = accuracy_score(test_df['misogynous'], pred_lr)\n",
    "print(\"Accuracy = {}\".format(acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17e08a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-misogynistic      0.801     0.834     0.817       517\n",
      "    misogynistic      0.814     0.778     0.796       483\n",
      "\n",
      "       micro avg      0.807     0.807     0.807      1000\n",
      "       macro avg      0.807     0.806     0.806      1000\n",
      "    weighted avg      0.807     0.807     0.807      1000\n",
      "\n",
      "Accuracy = 0.807\n"
     ]
    }
   ],
   "source": [
    "#### LOGREG WITH STEMMING\n",
    "LogReg_pipeline = Pipeline([('vect', stemmed_count_vect),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(solver='sag'))\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "lr_clf = LogReg_pipeline.fit(train_df[text_data_column], train_df['misogynous'])\n",
    "pred_lr = lr_clf.predict(test_df[text_data_column])\n",
    "print(classification_report(test_df['misogynous'], pred_lr, target_names=target_names, digits=3))\n",
    "acc_score = accuracy_score(test_df['misogynous'], pred_lr)\n",
    "print(\"Accuracy = {}\".format(acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efc799",
   "metadata": {},
   "source": [
    "## Decision Tree with Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33692fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-misogynistic      0.746     0.660     0.700       517\n",
      "    misogynistic      0.676     0.760     0.715       483\n",
      "\n",
      "       micro avg      0.708     0.708     0.708      1000\n",
      "       macro avg      0.711     0.710     0.708      1000\n",
      "    weighted avg      0.712     0.708     0.708      1000\n",
      "\n",
      "Accuracy = 0.708\n"
     ]
    }
   ],
   "source": [
    "#### Decision Tree WITH STEMMING\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "DT_pipeline = Pipeline([('vect', stemmed_count_vect),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', DecisionTreeClassifier())\n",
    "            ])\n",
    "\n",
    "\n",
    "\n",
    "dt_clf = DT_pipeline.fit(train_df[text_data_column], train_df['misogynous'])\n",
    "pred_lr = dt_clf.predict(test_df[text_data_column])\n",
    "print(classification_report(test_df['misogynous'], pred_lr, target_names=target_names, digits=3))\n",
    "acc_score = accuracy_score(test_df['misogynous'], pred_lr)\n",
    "print(\"Accuracy = {}\".format(acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2eb13d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLTK\n",
    "# Removing stop words\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), \n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "# Stemming Code\n",
    "\n",
    "import nltk\n",
    "# nltk.download()\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "    \n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
    "                             ('mnb', MultinomialNB(fit_prior=False))])\n",
    "\n",
    "text_mnb_stemmed = text_mnb_stemmed.fit(train_df[text_data_column], train_df['misogynous'])\n",
    "\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(test_df[text_data_column])\n",
    "\n",
    "np.mean(predicted_mnb_stemmed == test_df['misogynous'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83d0c83",
   "metadata": {},
   "source": [
    "## Storing TF-IDF features in pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e426c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 15993)\n",
      "(1000, 15993)\n",
      "(7000, 15993)\n",
      "(2000, 15993)\n",
      "0.805\n",
      "0.7605\n",
      "0.8735714285714286\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes\n",
    "# text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('mnb', MultinomialNB()),\n",
    " ])\n",
    "\n",
    "X_train_data = train_df[text_data_column]\n",
    "\n",
    "clf = text_mnb_stemmed.fit(X_train_data, train_df['misogynous'])\n",
    "\n",
    "\n",
    "tfidf_transformer = TfidfVectorizer(use_idf= True, stop_words = stop_words)\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_data)\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# text_clf = text_clf.fit(X_train_tfidf, train_df['misogynous'])\n",
    "\n",
    "\n",
    "\n",
    "# clf = MultinomialNB().fit(X_train_tfidf, train_df['misogynous'])\n",
    "\n",
    "# X_test_data = test_df[text_data_column]\n",
    "X_test = tfidf_transformer.transform(X_test_data)\n",
    "\n",
    "# X_val_data = val_df[text_data_column]\n",
    "X_val = tfidf_transformer.transform(X_val_data)\n",
    "\n",
    "# X_train_data = train_df[text_data_column]\n",
    "X_train = tfidf_transformer.transform(X_train_data)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "preds = clf.predict(X_test_data)\n",
    "score_nb = np.mean(preds == test_df['misogynous'])\n",
    "# print(predicted)\n",
    "print(score_nb)\n",
    "\n",
    "preds = clf.predict(X_val_data)\n",
    "score_nb = np.mean(preds == val_df['misogynous'])\n",
    "# print(predicted)\n",
    "print(score_nb)\n",
    "\n",
    "\n",
    "preds = clf.predict(X_train_data)\n",
    "score_nb = np.mean(preds == train_df['misogynous'])\n",
    "# print(predicted)\n",
    "print(score_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "343cc835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 12804)\n",
      "(7000, 12804)\n",
      "(2000, 12804)\n"
     ]
    }
   ],
   "source": [
    "X_train = clf.named_steps['tfidf'].transform(clf.named_steps['vect'].transform(X_train_data))\n",
    "X_val = clf.named_steps['tfidf'].transform(clf.named_steps['vect'].transform(X_val_data))\n",
    "X_test = clf.named_steps['tfidf'].transform(clf.named_steps['vect'].transform(X_test_data))\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9d1a8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12804)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_test.todense()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11099188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "tf_idf = {}\n",
    "\n",
    "tf_idf['train'] = np.array(X_train.todense())\n",
    "tf_idf['val'] = np.array(X_val.todense())\n",
    "tf_idf['test'] = np.array(X_test.todense())\n",
    "\n",
    "with open('tf_features.pickle', 'wb') as handle:\n",
    "    pickle.dump(tf_idf, handle, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac933db8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
